{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58198d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, LSTM, Dense, Bidirectional, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e866196",
   "metadata": {},
   "source": [
    "I start by importing the dataset that contains eight columns. The first one contains the comments to be preprocessed, the following six are labels indicating the presence or absence of a certain feature of the comment, a “clean” comment will have all labels of value 0. Finally, the last column contains the sum of the labels found in each comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e93688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>sum_injurious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  sum_injurious  \n",
       "0        0       0       0              0              0  \n",
       "1        0       0       0              0              0  \n",
       "2        0       0       0              0              0  \n",
       "3        0       0       0              0              0  \n",
       "4        0       0       0              0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Filter_Toxic_Comments_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9bc53",
   "metadata": {},
   "source": [
    "I assign to X the comments and to y the values of each label belonging to the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea0b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text'].values\n",
    "y = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2b6bc",
   "metadata": {},
   "source": [
    "Let's create train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09227a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9567b0c5",
   "metadata": {},
   "source": [
    "Let's create functions to preprocess the text, in the end a text will be returned that is free of special characters, stopwords (such as articles and prepositions) and already tokenized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c356ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Prende in ingresso del testo, rimuove i caratteri speciali e lo converte in minuscolo.\n",
    "    Restituisce poi il testo preprocessato.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    Prende in ingresso dei token ed elimina le stopwords. Restituisce i token \"filtrati\"\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "def preprocess_pipeline(text):\n",
    "    \"\"\"\n",
    "    Applica tutte le funzioni di preprocessing e restituisce dei token \"puliti\"\n",
    "    \"\"\"\n",
    "    text = preprocess_text(text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = remove_stopwords(tokens)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db938c",
   "metadata": {},
   "source": [
    "I apply preprocessing separately to the train and test set to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc0d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = [preprocess_pipeline(text) for text in X_train]\n",
    "\n",
    "X_test_preprocessed = [preprocess_pipeline(text) for text in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e0aa3",
   "metadata": {},
   "source": [
    "Let's create a tokenizer to convert tokens into numeric sequences. With the parameter num_words=10000 I indicate that the tokenizer will maintain a vocabulary of the 10,000 most frequent words in the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164e52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb4b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e11737",
   "metadata": {},
   "source": [
    "Applying tokenizer on train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e3ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences= tokenizer.texts_to_sequences(X_train_preprocessed)\n",
    "test_sequences= tokenizer.texts_to_sequences(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2829b73",
   "metadata": {},
   "source": [
    "Here we calculate vocabulary_size which is needed to correctly define the Embedding layer that maps words into dense vectors, and maxlen which is important to perform padding of sequences so that they all have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c54b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_index)+1\n",
    "maxlen = len(max(train_sequences,key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b46221",
   "metadata": {},
   "source": [
    "Let's apply padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d824f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train_sequences = pad_sequences(train_sequences,maxlen=maxlen)\n",
    "padded_test_sequences = pad_sequences(test_sequences,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a665ad",
   "metadata": {},
   "source": [
    "I create a callback so that I stop training a model if performance does not improve for a number of epochs. It will go to monitor val_loss and val_accuracy, if they do not improve for two epochs in a row the training ends. Restore_best_weights=True causes the model weights to be restored to the values that got the best val_loss before the termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5de2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, \n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8faee",
   "metadata": {},
   "source": [
    "We will now go on to compare three types of models: GRU (Gated Recurrent Unit), LSTM(Long short-term memory) and Bidirectional LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b5e0a",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea2795c",
   "metadata": {},
   "source": [
    "Here I create a sequential model. \n",
    "First we add an Embedding layer that projects each word into a dense vector of size 128. \n",
    "Then we add a GRU layer with 64 units and tanh activation function. This is the main recurrent layer that will process the embedded text sequences.\n",
    "Then we add a Dropout layer with a rate of 0.5 to help prevent overfitting during training. Finally we add a dense layer with 6 output nodes and sigmoid activation. We will use this construction pattern for the other two models as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6859baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 13:43:13.329383: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-05-31 13:43:13.329412: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-05-31 13:43:13.329415: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-05-31 13:43:13.329715: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-31 13:43:13.329730: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │    \u001b[38;5;34m24,832,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,870,278</span> (94.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,870,278\u001b[0m (94.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,870,278</span> (94.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,870,278\u001b[0m (94.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "model_GRU = Sequential()\n",
    "model_GRU.add(Embedding(vocabulary_size, 128))\n",
    "model_GRU.add(GRU(64,activation='tanh'))\n",
    "model_GRU.add(Dropout(0.5))\n",
    "model_GRU.add(Dense(6,activation='sigmoid'))\n",
    "model_GRU.build(input_shape=(None, maxlen))\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ea5ff",
   "metadata": {},
   "source": [
    "Let's compile the model using rmsprop as the optimizer and binary_crossentropy as the loss function since we are dealing with a binary classification, we choose accuracy as the metric to be evaluated during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd38a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c35af1",
   "metadata": {},
   "source": [
    "First let's train the model for five epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "656cc345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 13:43:13.992500: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 543ms/step - accuracy: 0.6535 - loss: 0.2115 - val_accuracy: 0.9867 - val_loss: 0.0737\n",
      "Epoch 2/5\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 479ms/step - accuracy: 0.9319 - loss: 0.0705 - val_accuracy: 0.9928 - val_loss: 0.0587\n",
      "Epoch 3/5\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 462ms/step - accuracy: 0.9317 - loss: 0.0584 - val_accuracy: 0.9928 - val_loss: 0.0551\n",
      "Epoch 4/5\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 466ms/step - accuracy: 0.9433 - loss: 0.0548 - val_accuracy: 0.9897 - val_loss: 0.0542\n",
      "Epoch 5/5\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 471ms/step - accuracy: 0.9358 - loss: 0.0521 - val_accuracy: 0.9928 - val_loss: 0.0537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31ea933d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GRU.fit(padded_train_sequences,y_train, \n",
    "                      validation_data=(padded_test_sequences,y_test), \n",
    "                      epochs= 5, batch_size=256, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38185ed",
   "metadata": {},
   "source": [
    "Then let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8819e6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 28ms/step - accuracy: 0.9932 - loss: 0.0526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05373097583651543, 0.9927933812141418]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GRU.evaluate(padded_test_sequences, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688b894",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eff8d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │    \u001b[38;5;34m24,832,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,882,438</span> (94.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,882,438\u001b[0m (94.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,882,438</span> (94.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,882,438\u001b[0m (94.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(Embedding(vocabulary_size, 128))\n",
    "model_LSTM.add(LSTM(64,activation='tanh'))\n",
    "model_LSTM.add(Dropout(0.5))\n",
    "model_LSTM.add(Dense(6,activation='sigmoid'))\n",
    "model_LSTM.build(input_shape=(None, maxlen))\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d625521",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e86a40e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 754ms/step - accuracy: 0.5725 - loss: 0.1886 - val_accuracy: 0.9869 - val_loss: 0.0817\n",
      "Epoch 2/5\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 984ms/step - accuracy: 0.9538 - loss: 0.0815 - val_accuracy: 0.9936 - val_loss: 0.0592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3177881d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM.fit(padded_train_sequences,y_train, \n",
    "                      validation_data=(padded_test_sequences,y_test), \n",
    "                      epochs= 5, batch_size=256, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b87bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.9873 - loss: 0.0798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08167001605033875, 0.9869027137756348]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM.evaluate(padded_test_sequences, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43a3dc",
   "metadata": {},
   "source": [
    "BIDIRECTIONAL LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "936f3cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │    \u001b[38;5;34m24,832,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,932,230</span> (95.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,932,230\u001b[0m (95.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,932,230</span> (95.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,932,230\u001b[0m (95.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "model_BiLSTM = Sequential()\n",
    "model_BiLSTM.add(Embedding(vocabulary_size, 128))\n",
    "model_BiLSTM.add(Bidirectional(LSTM(64,activation='tanh')))\n",
    "model_BiLSTM.add(Dropout(0.5))\n",
    "model_BiLSTM.add(Dense(6,activation='sigmoid'))\n",
    "model_BiLSTM.build(input_shape=(None, maxlen))\n",
    "model_BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a8b184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_BiLSTM.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c63fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 1s/step - accuracy: 0.7176 - loss: 0.1706 - val_accuracy: 0.9936 - val_loss: 0.0886\n",
      "Epoch 2/5\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 1s/step - accuracy: 0.9824 - loss: 0.0764 - val_accuracy: 0.9937 - val_loss: 0.0618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x38e4eb350>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BiLSTM.fit(padded_train_sequences,y_train, \n",
    "                      validation_data=(padded_test_sequences,y_test), \n",
    "                      epochs= 5, batch_size=256, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2598c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - accuracy: 0.9940 - loss: 0.0867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08855487406253815, 0.993639349937439]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BiLSTM.evaluate(padded_test_sequences, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047a70c",
   "metadata": {},
   "source": [
    "We'll use the last trained model. To test its operation we created a function that prints on screen the comment, the labels assigned to it, and the labels predicted by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de03bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comment_and_labels(X_test, y_test, y_pred, index):\n",
    "    print(\"Commento:\")\n",
    "    print(X_test[index])\n",
    "    print(\"\\nLabel effettive:\")\n",
    "    print(\"Toxic: {}, Severe Toxic: {}, Obscene: {}, Threat: {}, Insult: {}, Identity Hate: {}\".format(\n",
    "        y_test[index][0], y_test[index][1], y_test[index][2], y_test[index][3], y_test[index][4], y_test[index][5]))\n",
    "    print(\"\\nLabel predette:\")\n",
    "    print(\"Toxic: {}, Severe Toxic: {}, Obscene: {}, Threat: {}, Insult: {}, Identity Hate: {}\".format(\n",
    "        y_pred[index][0], y_pred[index][1], y_pred[index][2], y_pred[index][3], y_pred[index][4], y_pred[index][5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "706b944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_BiLSTM.predict(padded_test_sequences)\n",
    "y_pred = (y_pred > 0.3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6134ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commento:\n",
      "\"::::Doing a word search is not reading the article. Others can take it from me that this is precisely what Coase says. I will be happy to explain to anyone else who is interested (not you either Luke). THF is not capable of engaging in rational debate on these issues. He has a clear conflict of interest, because he is a professional lobbyist, and appears to be well trained in this Karl Rove style of engagement.  \n",
      "\n",
      "\"\n",
      "\n",
      "Label effettive:\n",
      "Toxic: 0, Severe Toxic: 0, Obscene: 0, Threat: 0, Insult: 0, Identity Hate: 0\n",
      "\n",
      "Label predette:\n",
      "Toxic: 0, Severe Toxic: 0, Obscene: 0, Threat: 0, Insult: 0, Identity Hate: 0\n"
     ]
    }
   ],
   "source": [
    "print_comment_and_labels(X_test, y_test, y_pred, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa8609f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commento:\n",
      "YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER! YOU ARE A MOTHJER FUCKER COCKSUCKER!\n",
      "\n",
      "Label effettive:\n",
      "Toxic: 1, Severe Toxic: 1, Obscene: 1, Threat: 0, Insult: 1, Identity Hate: 0\n",
      "\n",
      "Label predette:\n",
      "Toxic: 1, Severe Toxic: 1, Obscene: 1, Threat: 0, Insult: 1, Identity Hate: 0\n"
     ]
    }
   ],
   "source": [
    "print_comment_and_labels(X_test, y_test, y_pred, 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e31ef",
   "metadata": {},
   "source": [
    "The model works! The right labels for offensive comments are predicted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
